{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduction of DECAF: Generating Fair Synthetic Data Using Causally-Aware Generative Networks\n",
    "\n",
    "In this notebook we reproduce the results from the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler \n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Adult dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    \"age\",\n",
    "    \"workclass\",\n",
    "    \"fnlwgt\",\n",
    "    \"education\",\n",
    "    \"education-num\",\n",
    "    \"marital-status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"sex\",\n",
    "    \"capital-gain\",\n",
    "    \"capital-loss\",\n",
    "    \"hours-per-week\",\n",
    "    \"native-country\",\n",
    "    \"income\",\n",
    "]\n",
    "def load_adult():\n",
    "    \"\"\"Load the Adult dataset in a pandas dataframe\"\"\"\n",
    "\n",
    "    path = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "    names = [\n",
    "        \"age\",\n",
    "        \"workclass\",\n",
    "        \"fnlwgt\",\n",
    "        \"education\",\n",
    "        \"education-num\",\n",
    "        \"marital-status\",\n",
    "        \"occupation\",\n",
    "        \"relationship\",\n",
    "        \"race\",\n",
    "        \"sex\",\n",
    "        \"capital-gain\",\n",
    "        \"capital-loss\",\n",
    "        \"hours-per-week\",\n",
    "        \"native-country\",\n",
    "        \"income\",\n",
    "    ]\n",
    "    df = pd.read_csv(path, names=names, index_col=False)\n",
    "    df = df.applymap(lambda x: x.strip() if type(x) is str else x)\n",
    "\n",
    "    for col in df:\n",
    "        if df[col].dtype == \"object\":\n",
    "            df = df[df[col] != \"?\"]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country income  \n",
       "0          2174             0              40  United-States  <=50K  \n",
       "1             0             0              13  United-States  <=50K  \n",
       "2             0             0              40  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4             0             0              40           Cuba  <=50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display examples from the dataset\n",
    "adult_dataset = load_adult()\n",
    "adult_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test_data(df):\n",
    "    \"\"\"Get GAN training data from Adult dataset\"\"\"\n",
    "    replace = [\n",
    "        [\n",
    "            \"Private\",\n",
    "            \"Self-emp-not-inc\",\n",
    "            \"Self-emp-inc\",\n",
    "            \"Federal-gov\",\n",
    "            \"Local-gov\",\n",
    "            \"State-gov\",\n",
    "            \"Without-pay\",\n",
    "            \"Never-worked\",\n",
    "        ],\n",
    "        [\n",
    "            \"Bachelors\",\n",
    "            \"Some-college\",\n",
    "            \"11th\",\n",
    "            \"HS-grad\",\n",
    "            \"Prof-school\",\n",
    "            \"Assoc-acdm\",\n",
    "            \"Assoc-voc\",\n",
    "            \"9th\",\n",
    "            \"7th-8th\",\n",
    "            \"12th\",\n",
    "            \"Masters\",\n",
    "            \"1st-4th\",\n",
    "            \"10th\",\n",
    "            \"Doctorate\",\n",
    "            \"5th-6th\",\n",
    "            \"Preschool\",\n",
    "        ],\n",
    "        [\n",
    "            \"Married-civ-spouse\",\n",
    "            \"Divorced\",\n",
    "            \"Never-married\",\n",
    "            \"Separated\",\n",
    "            \"Widowed\",\n",
    "            \"Married-spouse-absent\",\n",
    "            \"Married-AF-spouse\",\n",
    "        ],\n",
    "        [\n",
    "            \"Tech-support\",\n",
    "            \"Craft-repair\",\n",
    "            \"Other-service\",\n",
    "            \"Sales\",\n",
    "            \"Exec-managerial\",\n",
    "            \"Prof-specialty\",\n",
    "            \"Handlers-cleaners\",\n",
    "            \"Machine-op-inspct\",\n",
    "            \"Adm-clerical\",\n",
    "            \"Farming-fishing\",\n",
    "            \"Transport-moving\",\n",
    "            \"Priv-house-serv\",\n",
    "            \"Protective-serv\",\n",
    "            \"Armed-Forces\",\n",
    "        ],\n",
    "        [\n",
    "            \"Wife\",\n",
    "            \"Own-child\",\n",
    "            \"Husband\",\n",
    "            \"Not-in-family\",\n",
    "            \"Other-relative\",\n",
    "            \"Unmarried\",\n",
    "        ],\n",
    "        [\"White\", \"Asian-Pac-Islander\", \"Amer-Indian-Eskimo\", \"Other\", \"Black\"],\n",
    "        [\"Female\", \"Male\"],\n",
    "        [\n",
    "            \"United-States\",\n",
    "            \"Cambodia\",\n",
    "            \"England\",\n",
    "            \"Puerto-Rico\",\n",
    "            \"Canada\",\n",
    "            \"Germany\",\n",
    "            \"Outlying-US(Guam-USVI-etc)\",\n",
    "            \"India\",\n",
    "            \"Japan\",\n",
    "            \"Greece\",\n",
    "            \"South\",\n",
    "            \"China\",\n",
    "            \"Cuba\",\n",
    "            \"Iran\",\n",
    "            \"Honduras\",\n",
    "            \"Philippines\",\n",
    "            \"Italy\",\n",
    "            \"Poland\",\n",
    "            \"Jamaica\",\n",
    "            \"Vietnam\",\n",
    "            \"Mexico\",\n",
    "            \"Portugal\",\n",
    "            \"Ireland\",\n",
    "            \"France\",\n",
    "            \"Dominican-Republic\",\n",
    "            \"Laos\",\n",
    "            \"Ecuador\",\n",
    "            \"Taiwan\",\n",
    "            \"Haiti\",\n",
    "            \"Columbia\",\n",
    "            \"Hungary\",\n",
    "            \"Guatemala\",\n",
    "            \"Nicaragua\",\n",
    "            \"Scotland\",\n",
    "            \"Thailand\",\n",
    "            \"Yugoslavia\",\n",
    "            \"El-Salvador\",\n",
    "            \"Trinadad&Tobago\",\n",
    "            \"Peru\",\n",
    "            \"Hong\",\n",
    "            \"Holand-Netherlands\",\n",
    "        ],\n",
    "        [\">50K\", \"<=50K\"],\n",
    "    ]\n",
    "\n",
    "    for row in replace:\n",
    "        df = df.replace(row, range(len(row)))\n",
    "\n",
    "    df = df.values\n",
    "    X = df[:, :14].astype(np.uint32)\n",
    "    X = MinMaxScaler().fit_transform(X)\n",
    "    for row in X:\n",
    "        if row[9]>0:\n",
    "            row[9] = 1\n",
    "        elif row[9]<0:\n",
    "            row[9] = 0\n",
    "    y = df[:, 14].astype(np.uint8)\n",
    "\n",
    "    return train_test_split(X, y, test_size=2000, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DAG for Adult dataset\n",
    "dag = [\n",
    "    # Edges from race\n",
    "    ['race', 'occupation'],\n",
    "    ['race', 'income'],\n",
    "    ['race', 'hours-per-week'],\n",
    "    ['race', 'education'],\n",
    "    ['race', 'marital-status'],\n",
    "\n",
    "    # Edges from age\n",
    "    ['age', 'occupation'],\n",
    "    ['age', 'hours-per-week'],\n",
    "    ['age', 'income'],\n",
    "    ['age', 'workclass'],\n",
    "    ['age', 'marital-status'],\n",
    "    ['age', 'education'],\n",
    "    ['age', 'relationship'],\n",
    "    \n",
    "    # Edges from sex\n",
    "    ['sex', 'occupation'],\n",
    "    ['sex', 'marital-status'],\n",
    "    ['sex', 'income'],\n",
    "    ['sex', 'workclass'],\n",
    "    ['sex', 'education'],\n",
    "    ['sex', 'relationship'],\n",
    "    \n",
    "    # Edges from native country\n",
    "    ['native-country', 'marital-status'],\n",
    "    ['native-country', 'hours-per-week'],\n",
    "    ['native-country', 'education'],\n",
    "    ['native-country', 'workclass'],\n",
    "    ['native-country', 'income'],\n",
    "    ['native-country', 'relationship'],\n",
    "    \n",
    "    # Edges from marital status\n",
    "    ['marital-status', 'occupation'],\n",
    "    ['marital-status', 'hours-per-week'],\n",
    "    ['marital-status', 'income'],\n",
    "    ['marital-status', 'workclass'],\n",
    "    ['marital-status', 'relationship'],\n",
    "    ['marital-status', 'education'],\n",
    "    \n",
    "    # Edges from education\n",
    "    ['education', 'occupation'],\n",
    "    ['education', 'hours-per-week'],\n",
    "    ['education', 'income'],\n",
    "    ['education', 'workclass'],\n",
    "    ['education', 'relationship'],\n",
    "    \n",
    "    # All remaining edges\n",
    "    ['occupation', 'income'],\n",
    "    ['hours-per-week', 'income'],\n",
    "    ['workclass', 'income'],\n",
    "    ['relationship', 'income'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dag_to_idx(df, dag):\n",
    "    \"\"\"Convert columns in a DAG to the corresponding indices.\"\"\"\n",
    "\n",
    "    dag_idx = []\n",
    "    for edge in dag:\n",
    "        dag_idx.append([df.columns.get_loc(edge[0]), df.columns.get_loc(edge[1])])\n",
    "\n",
    "    return dag_idx\n",
    "\n",
    "def create_bias_dict(df, edge_map):\n",
    "    \"\"\"\n",
    "    Convert the given edge tuples to a bias dict used for generating\n",
    "    debiased synthetic data.\n",
    "    \"\"\"\n",
    "    bias_dict = {}\n",
    "    for key, val in edge_map.items():\n",
    "        bias_dict[df.columns.get_loc(key)] = [df.columns.get_loc(f) for f in val]\n",
    "    \n",
    "    return bias_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8, 6], [8, 14], [8, 12], [8, 3], [8, 5], [0, 6], [0, 12], [0, 14], [0, 1], [0, 5], [0, 3], [0, 7], [9, 6], [9, 5], [9, 14], [9, 1], [9, 3], [9, 7], [13, 5], [13, 12], [13, 3], [13, 1], [13, 14], [13, 7], [5, 6], [5, 12], [5, 14], [5, 1], [5, 7], [5, 3], [3, 6], [3, 12], [3, 14], [3, 1], [3, 7], [6, 14], [12, 14], [1, 14], [7, 14]]\n"
     ]
    }
   ],
   "source": [
    "# Convert the DAG to one that can be provided to the DECAF model\n",
    "dag_seed = dag_to_idx(adult_dataset, dag)\n",
    "print(dag_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias dict FTU: {14: [9]}\n",
      "Bias dict DP: {14: [6, 12, 5, 3, 9, 1, 7]}\n",
      "Bias dict CF: {14: [5, 9]}\n"
     ]
    }
   ],
   "source": [
    "bias_dict_ftu = create_bias_dict(adult_dataset, {'income': ['sex']})\n",
    "print('Bias dict FTU:', bias_dict_ftu)\n",
    "\n",
    "bias_dict_dp = create_bias_dict(adult_dataset, {'income': [\n",
    "    'occupation', 'hours-per-week', 'marital-status', 'education', 'sex',\n",
    "    'workclass', 'relationship']})\n",
    "print('Bias dict DP:', bias_dict_dp)\n",
    "\n",
    "bias_dict_cf = create_bias_dict(adult_dataset, {'income': [\n",
    "    'marital-status', 'sex']})\n",
    "print('Bias dict CF:', bias_dict_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28162.000000</td>\n",
       "      <td>28162.000000</td>\n",
       "      <td>28162.000000</td>\n",
       "      <td>28162.000000</td>\n",
       "      <td>28162.000000</td>\n",
       "      <td>28162.000000</td>\n",
       "      <td>28162.000000</td>\n",
       "      <td>28162.000000</td>\n",
       "      <td>28162.000000</td>\n",
       "      <td>28162.000000</td>\n",
       "      <td>28162.000000</td>\n",
       "      <td>28162.000000</td>\n",
       "      <td>28162.000000</td>\n",
       "      <td>28162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.293559</td>\n",
       "      <td>0.123127</td>\n",
       "      <td>0.119433</td>\n",
       "      <td>0.224449</td>\n",
       "      <td>0.608129</td>\n",
       "      <td>0.175934</td>\n",
       "      <td>0.364138</td>\n",
       "      <td>0.479036</td>\n",
       "      <td>0.111178</td>\n",
       "      <td>0.674988</td>\n",
       "      <td>0.010786</td>\n",
       "      <td>0.020321</td>\n",
       "      <td>0.407120</td>\n",
       "      <td>0.037902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.180110</td>\n",
       "      <td>0.243890</td>\n",
       "      <td>0.071397</td>\n",
       "      <td>0.228510</td>\n",
       "      <td>0.169811</td>\n",
       "      <td>0.195276</td>\n",
       "      <td>0.229000</td>\n",
       "      <td>0.246059</td>\n",
       "      <td>0.299202</td>\n",
       "      <td>0.468388</td>\n",
       "      <td>0.073319</td>\n",
       "      <td>0.092962</td>\n",
       "      <td>0.122538</td>\n",
       "      <td>0.140839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070592</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.273973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111883</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.410959</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.151693</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  28162.000000  28162.000000  28162.000000  28162.000000  28162.000000   \n",
       "mean       0.293559      0.123127      0.119433      0.224449      0.608129   \n",
       "std        0.180110      0.243890      0.071397      0.228510      0.169811   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.150685      0.000000      0.070592      0.066667      0.533333   \n",
       "50%        0.273973      0.000000      0.111883      0.200000      0.600000   \n",
       "75%        0.410959      0.166667      0.151693      0.200000      0.800000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  28162.000000  28162.000000  28162.000000  28162.000000  28162.000000   \n",
       "mean       0.175934      0.364138      0.479036      0.111178      0.674988   \n",
       "std        0.195276      0.229000      0.246059      0.299202      0.468388   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.153846      0.400000      0.000000      0.000000   \n",
       "50%        0.166667      0.307692      0.400000      0.000000      1.000000   \n",
       "75%        0.333333      0.538462      0.600000      0.000000      1.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                 10            11            12            13  \n",
       "count  28162.000000  28162.000000  28162.000000  28162.000000  \n",
       "mean       0.010786      0.020321      0.407120      0.037902  \n",
       "std        0.073319      0.092962      0.122538      0.140839  \n",
       "min        0.000000      0.000000      0.000000      0.000000  \n",
       "25%        0.000000      0.000000      0.397959      0.000000  \n",
       "50%        0.000000      0.000000      0.397959      0.000000  \n",
       "75%        0.000000      0.000000      0.448980      0.000000  \n",
       "max        1.000000      1.000000      1.000000      1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get training and testing data\n",
    "X_train, X_test, y_train, y_test = load_train_test_data(adult_dataset)\n",
    "\n",
    "pd.DataFrame(X_train).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an MLP\n",
    "mlp = MLPClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(mlp, x = X_test, y = y_test):\n",
    "    \"\"\"Helper function that prints evaluation metrics.\"\"\"\n",
    "\n",
    "    y_pred = mlp.predict(x[:, :14])\n",
    "\n",
    "    prec = precision_score(y, y_pred)\n",
    "    rec = recall_score(y, y_pred)\n",
    "    roc = roc_auc_score(y, y_pred)\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    \n",
    "    return prec, rec, roc, acc\n",
    "\n",
    "def cal_DP(mlp, X_test):\n",
    "    \"\"\"Calculate fairness metric DP\"\"\"\n",
    "    \n",
    "    X_test_df = pd.DataFrame(X_test, columns = names[:-1]) \n",
    "    X_test_0 = X_test_df[X_test_df[\"sex\"] <0.5]\n",
    "    X_test_1 = X_test_df[X_test_df[\"sex\"] >0.5]\n",
    "    dp = abs(np.mean(mlp.predict(X_test_0)) - np.mean(mlp.predict(X_test_1)))\n",
    "    \n",
    "    return dp\n",
    "    \n",
    "    \n",
    "# def FTU(X_test, X_synth, y_synth):\n",
    "#     \"\"\"Calculate fairness metric FTU\"\"\"\n",
    "#     X_synth_0 = np.delete(X_synth,9,1) #Delete column of protected attribute\n",
    "#     X_test_0 = np.delete(X_test,9,1) #Delete column of protected attribute\n",
    "    \n",
    "#     mlp_0 = MLPClassifier().fit(X_synth_0, y_synth)\n",
    "#     mlp_1 = MLPClassifier().fit(X_synth, y_synth)\n",
    "    \n",
    "#     ftu = abs(mlp_0.predict_proba(X_test_0) - mlp_1.predict_proba(X_test))\n",
    "    \n",
    "#     print(\"FTU is: \", np.sum(ftu)/len(X_test))\n",
    "\n",
    "def cal_FTU(mlp, X_test):\n",
    "    \"\"\"Calculate fairness metric DP\"\"\"\n",
    "    \n",
    "    X_test_df = pd.DataFrame(X_test, columns = names[:-1])\n",
    "    X_test_0 = X_test_df.assign(sex = 0)\n",
    "    X_test_1 = X_test_df.assign(sex = 1)\n",
    "\n",
    "    ftu = abs(np.mean(mlp.predict(X_test_0)) - np.mean(mlp.predict(X_test_1)))\n",
    "\n",
    "    return ftu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.8788839568801522 recall:  0.9227696404793608 roc_auc:  0.769617751966588\n",
      "0.17865761243287315\n",
      "0.028000000000000025\n"
     ]
    }
   ],
   "source": [
    "# Evaluate original data\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "print(\n",
    "    \"precision: \", precision_score(y_test, y_pred),\n",
    "    \"recall: \", recall_score(y_test, y_pred),\n",
    "    \"roc_auc: \", roc_auc_score(y_test, y_pred),\n",
    ")\n",
    "\n",
    "print(cal_DP(mlp, X_test))\n",
    "print(cal_FTU(mlp, X_test))\n",
    "#FTU(X_test = X_test, X_synth = X_test, y_synth = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECAF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | generator     | Generator_causal | 134 K \n",
      "1 | discriminator | Discriminator    | 43.6 K\n",
      "---------------------------------------------------\n",
      "178 K     Trainable params\n",
      "225       Non-trainable params\n",
      "178 K     Total params\n",
      "0.713     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised adjacency matrix as parsed:\n",
      " Parameter containing:\n",
      "tensor([[0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1.],\n",
      "        [0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2975b351ec444dab93baf4ce7e082e4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-b421cb6587d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'DECAF.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DECAF.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Users\\anaconda3\\envs\\py36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1453\u001b[0m         \u001b[1;31m# copy state_dict so _load_from_state_dict can modify it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1454\u001b[0m         \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_metadata'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1455\u001b[1;33m         \u001b[0mstate_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1456\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1457\u001b[0m             \u001b[1;31m# mypy isn't aware that \"_metadata\" exists in state_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "from models.DECAF import DECAF\n",
    "from data import DataModule\n",
    "\n",
    "train_data = np.column_stack((X_train, y_train))\n",
    "dm = DataModule(train_data)\n",
    "\n",
    "model = DECAF(\n",
    "    dm.dims[0],\n",
    "    dag_seed=dag_seed,\n",
    "    h_dim=200,\n",
    "    lr=0.5e-3,\n",
    "    batch_size=64,\n",
    "    lambda_privacy=0,\n",
    "    lambda_gp=10,\n",
    "    d_updates=10,\n",
    "    alpha=2,\n",
    "    rho=2,\n",
    "    weight_decay=1e-2,\n",
    "    grad_dag_loss=False,\n",
    "    l1_g=0,\n",
    "    l1_W=1e-4,\n",
    "    p_gen=-1,\n",
    "    use_mask=True,\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=10, logger=False)\n",
    "trainer.fit(model, dm)\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), 'DECAF.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('DECAF.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(biased_edges={}):\n",
    "    \"\"\"Generate synthetic data which is also optionally debiased.\"\"\"\n",
    "    X_synth = (\n",
    "        model.gen_synthetic(\n",
    "            dm.dataset.x,\n",
    "            gen_order = model.get_gen_order(),\n",
    "            biased_edges=biased_edges,\n",
    "        )\n",
    "        .detach()\n",
    "        .numpy()\n",
    "    )\n",
    "\n",
    "    return X_synth[:, :14], np.rint(X_synth[:,14]).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate DECAF-ND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                | 0/10 [00:00<?, ?it/s]E:\\Users\\anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      " 10%|█████▌                                                  | 1/10 [01:19<11:59, 79.96s/it]E:\\Users\\anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      " 20%|███████████▏                                            | 2/10 [02:39<10:39, 79.92s/it]E:\\Users\\anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      " 30%|████████████████▊                                       | 3/10 [03:57<09:14, 79.22s/it]E:\\Users\\anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      " 40%|██████████████████████▍                                 | 4/10 [05:16<07:55, 79.22s/it]E:\\Users\\anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      " 50%|████████████████████████████                            | 5/10 [06:35<06:35, 79.03s/it]E:\\Users\\anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      " 60%|█████████████████████████████████▌                      | 6/10 [07:52<05:14, 78.53s/it]E:\\Users\\anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      " 70%|███████████████████████████████████████▏                | 7/10 [09:11<03:55, 78.64s/it]E:\\Users\\anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      " 80%|████████████████████████████████████████████▊           | 8/10 [10:30<02:37, 78.87s/it]E:\\Users\\anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      " 90%|██████████████████████████████████████████████████▍     | 9/10 [11:50<01:18, 78.99s/it]E:\\Users\\anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "100%|███████████████████████████████████████████████████████| 10/10 [13:09<00:00, 78.99s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prec_mean': 0.8664639939335135,\n",
       " 'prec_std': 0.0014512173391180603,\n",
       " 'rec_mean': 0.9322237017310252,\n",
       " 'rec_std': 0.002396804260985351,\n",
       " 'roc_mean': 0.7494451841988461,\n",
       " 'roc_std': 0.0025876743951792776,\n",
       " 'dp_mean': 0.04024304608968612,\n",
       " 'dp_std': 0.0027883824738367848,\n",
       " 'ftu_mean': 0.023695050067466826,\n",
       " 'ftu_std': 0.002187243769100062}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_multi(model, mlp, times =10, y_the =\"generated\", biased_edges={} ):\n",
    "    prec_list = []\n",
    "    rec_list = []\n",
    "    roc_list = []\n",
    "    dp_list =[]\n",
    "    ftu_list=[]\n",
    "\n",
    "    for i in tqdm(range(times)):\n",
    "        X_synth, y_synth = generate_synthetic_data(biased_edges)\n",
    "        #X_synth_train, _, y_synth_train, _ = train_test_split(X_synth, y_synth, test_size=2000, stratify=y_synth)\n",
    "        \n",
    "        if y_the == \"predicted\":\n",
    "            y_synth = mlp.predict(X_synth)\n",
    "        random.seed(i)\n",
    "        mlp_synth = MLPClassifier().fit(X_synth, y_synth)\n",
    "\n",
    "        prec, rec, roc, acc = eval_model(mlp_synth)\n",
    "        prec_list.append(prec)\n",
    "        rec_list.append(rec)\n",
    "        roc_list.append(roc)\n",
    "        \n",
    "        dp =  cal_DP(mlp_synth, X_test=X_synth) \n",
    "        ftu = cal_FTU(mlp_synth, X_test=X_synth) \n",
    "        dp_list.append(dp)\n",
    "        ftu_list.append(ftu)\n",
    "    result={\"prec_mean\":np.mean(prec_list),\"prec_std\": np.std(prec_list),\n",
    "           \"rec_mean\":np.mean(rec_list),\"rec_std\": np.std(rec_list),\n",
    "           \"roc_mean\":np.mean(roc_list),\"roc_std\": np.std(roc_list),\n",
    "           \"dp_mean\":np.mean(dp_list),\"dp_std\": np.std(dp_list),\n",
    "           \"ftu_mean\":np.mean(ftu_list),\"ftu_std\": np.std(ftu_list),}\n",
    "\n",
    "    return result\n",
    "\n",
    "DECAF_ND_result_pred = train_multi(model, mlp, times =10, y_the =\"predicted\", biased_edges={} )\n",
    "DECAF_ND_result_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.01082063e-01 1.46451075e-05 2.05060229e-01 ... 7.43558980e-04\n",
      "  2.55349755e-01 6.30534759e-19]\n",
      " [3.78006548e-01 1.09433067e-08 1.43484667e-01 ... 1.56329976e-14\n",
      "  3.65474403e-01 2.04087659e-14]\n",
      " [1.05403677e-01 7.49660611e-01 2.53465891e-01 ... 6.37287261e-16\n",
      "  4.94337171e-01 1.36388510e-22]\n",
      " ...\n",
      " [4.74419177e-01 2.03077008e-07 3.52555066e-02 ... 1.88798919e-01\n",
      "  5.99800408e-01 2.05215671e-11]\n",
      " [9.05574709e-02 1.13401876e-03 7.38045722e-02 ... 6.81791781e-03\n",
      "  5.24084389e-01 2.82830459e-21]\n",
      " [6.52654320e-02 7.67396437e-03 1.07312292e-01 ... 4.61885124e-04\n",
      "  2.39931121e-01 4.82060132e-05]]\n",
      "test on real data\n",
      "prec : 0.7577184720041863\n",
      "rec : 0.9640479360852197\n",
      "roc : 0.5171645302916058\n",
      "dp : 0.046538705123522095\n",
      "ftu : 0.02208649953838504\n",
      "**************\n",
      "test on synth data\n",
      "prec : 0.7827676240208877\n",
      "rec : 0.9765472312703581\n",
      "roc : 0.5409617876781898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data\n",
    "X_synth, y_synth = generate_synthetic_data()\n",
    "print(X_synth)\n",
    "X_synth_train, X_synth_test, y_synth_train, y_synth_test = train_test_split(X_synth, y_synth, test_size=2000, stratify=y_synth)\n",
    "\n",
    "\n",
    "# Train downstream model and eval\n",
    "print(\"test on real data\")\n",
    "ndmlp = MLPClassifier().fit(X_synth_train, y_synth_train)\n",
    "\n",
    "prec, rec, roc, acc = np.mean([eval_model(ndmlp) for i in range(1)], axis=0)\n",
    "dp = np.mean([ cal_DP(ndmlp, X_test=X_synth) for i in range(1)])\n",
    "ftu = np.mean([ cal_FTU(ndmlp, X_test=X_synth) for i in range(1)])\n",
    "print(\"prec :\",prec) \n",
    "print(\"rec :\",rec)\n",
    "print(\"roc :\",roc) \n",
    "print(\"dp :\",dp) \n",
    "print(\"ftu :\",ftu) \n",
    "\n",
    "\n",
    "print(\"**************\")\n",
    "print(\"test on synth data\")\n",
    "# the weird thing they did in original code\n",
    "#eval_model(ndmlp, X_synth_test, y_synth_test)\n",
    "prec, rec, roc, acc = np.mean([eval_model(ndmlp, X_synth_test, y_synth_test) for i in range(3)], axis=0)\n",
    "print(\"prec :\",prec) \n",
    "print(\"rec :\",rec)\n",
    "print(\"roc :\",roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test on real data\n",
      "prec : 0.8668326073428749\n",
      "rec : 0.9274300932090546\n",
      "roc : 0.7488556088535232\n",
      "acc : 0.8385\n",
      "dp : 0.10046931846391072\n",
      "ftu : 0.058554079965911554\n",
      "**************\n",
      "test on synth data\n",
      "prec : 0.988404196576477\n",
      "rec : 0.9905921416712783\n",
      "roc : 0.940891925757919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_synth = mlp.predict(X_synth)\n",
    "X_synth_train, X_synth_test, y_synth_train, y_synth_test = train_test_split(X_synth, y_synth, test_size=2000, stratify=y_synth)\n",
    "\n",
    "# Train downstream model and eval\n",
    "ndmlp = MLPClassifier().fit(X_synth_train, y_synth_train)\n",
    "\n",
    "print(\"test on real data\")\n",
    "p_r_r_a = eval_model(ndmlp) \n",
    "prec, rec, roc, acc = p_r_r_a\n",
    "\n",
    "dp = cal_DP(ndmlp, X_test=X_synth) \n",
    "ftu = cal_FTU(ndmlp, X_test=X_synth)\n",
    "\n",
    "print(\"prec :\", prec) \n",
    "print(\"rec :\", rec) \n",
    "print(\"roc :\", roc) \n",
    "print(\"acc :\", acc) \n",
    "\n",
    "print(\"dp :\", dp)\n",
    "print(\"ftu :\", ftu)\n",
    "\n",
    "print(\"**************\")\n",
    "print(\"test on synth data\")\n",
    "# the weird thing they did in original code\n",
    "#eval_model(ndmlp, X_synth_test, y_synth_test)\n",
    "\n",
    "prec, rec, roc, acc = np.mean([eval_model(ndmlp, X_synth_test, y_synth_test) for i in range(3)], axis=0)\n",
    "print(\"prec :\",prec) \n",
    "print(\"rec :\",rec)\n",
    "print(\"roc :\",roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate DECAF-FTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec : 0.7669172932330827\n",
      "rec : 0.9507323568575233\n",
      "roc : 0.5396232065412115\n",
      "dp is:  0.0205746510105419\n",
      "ftu is:  0.023648888573254756\n",
      "prec : 0.7940379403794038\n",
      "rec : 0.9593975114603799\n",
      "roc : 0.5780074238062999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data\n",
    "X_synth, y_synth = generate_synthetic_data(biased_edges=bias_dict_ftu)\n",
    "X_synth_train, X_synth_test, y_synth_train, y_synth_test = train_test_split(X_synth, y_synth, test_size=2000, stratify=y_synth)\n",
    "\n",
    "# Train downstream model and eval\n",
    "ftumlp = MLPClassifier().fit(X_synth_train, y_synth_train)\n",
    "prec, rec, roc, acc = eval_model(ftumlp)\n",
    "print(\"prec :\", prec) \n",
    "print(\"rec :\", rec) \n",
    "print(\"roc :\", roc) \n",
    " \n",
    "\n",
    "ftu = cal_FTU(ftumlp, X_test=X_synth)\n",
    "dp = cal_DP(ftumlp, X_test=X_synth)\n",
    "print(\"dp is: \", dp)\n",
    "print(\"ftu is: \", ftu)\n",
    "\n",
    "# the weird thing they did in original code\n",
    "prec, rec, roc, acc = eval_model(ftumlp, X_synth_test, y_synth_test)\n",
    "print(\"prec :\", prec) \n",
    "print(\"rec :\", rec) \n",
    "print(\"roc :\", roc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec : 0.8650990099009901\n",
      "rec : 0.9307589880159787\n",
      "roc : 0.7465039919999572\n",
      "dp is:  0.0878861454951182\n",
      "ftu is:  0.04889567502308079\n",
      "prec : 0.9900607399226946\n",
      "rec : 0.9939024390243902\n",
      "roc : 0.9510328521652563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_synth = mlp.predict(X_synth)# Generate synthetic data\n",
    "X_synth_train, X_synth_test, y_synth_train, y_synth_test = train_test_split(X_synth, y_synth, test_size=2000, stratify=y_synth)\n",
    "\n",
    "ftumlp = MLPClassifier().fit(X_synth_train, y_synth_train)\n",
    "prec, rec, roc, acc = eval_model(ftumlp)\n",
    "print(\"prec :\", prec) \n",
    "print(\"rec :\", rec) \n",
    "print(\"roc :\", roc) \n",
    " \n",
    "\n",
    "ftu = cal_FTU(ftumlp, X_test=X_synth)\n",
    "dp = cal_DP(ftumlp, X_test=X_synth)\n",
    "print(\"dp is: \", dp)\n",
    "print(\"ftu is: \", ftu)\n",
    "\n",
    "# the weird thing they did in original code\n",
    "prec, rec, roc, acc = eval_model(ftumlp, X_synth_test, y_synth_test)\n",
    "print(\"prec :\", prec) \n",
    "print(\"rec :\", rec) \n",
    "print(\"roc :\", roc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate DECAF-DP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec : 0.7619532044760936\n",
      "rec : 0.9973368841544608\n",
      "roc : 0.5127353622211883\n",
      "dp is:  0.0004659545662266673\n",
      "ftu is:  0.00031957957531425496\n",
      "prec : 0.7738869434717359\n",
      "rec : 0.9993540051679587\n",
      "roc : 0.49967700258397935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data\n",
    "X_synth, y_synth = generate_synthetic_data(biased_edges=bias_dict_dp)\n",
    "X_synth_train, X_synth_test, y_synth_train, y_synth_test = train_test_split(X_synth, y_synth, test_size=2000, stratify=y_synth)\n",
    "\n",
    "\n",
    "# Train downstream model and eval\n",
    "dpmlp = MLPClassifier().fit(X_synth_train, y_synth_train)\n",
    "prec, rec, roc, acc = eval_model(dpmlp)\n",
    "print(\"prec :\", prec) \n",
    "print(\"rec :\", rec) \n",
    "print(\"roc :\", roc_mean) \n",
    "\n",
    "ftu = cal_FTU(dpmlp, X_test=X_synth)\n",
    "dp = cal_DP(dpmlp, X_test=X_synth)\n",
    "print(\"dp is: \", dp)\n",
    "print(\"ftu is: \", ftu)\n",
    "\n",
    "\n",
    "# the weird thing they did in original code\n",
    "prec, rec, roc, acc = eval_model(dpmlp, X_synth_test, y_synth_test)\n",
    "print(\"prec :\", prec) \n",
    "print(\"rec :\", rec) \n",
    "print(\"roc :\", roc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec : 0.8670377241805813\n",
      "rec : 0.933422103861518\n",
      "roc : 0.7508475981154978\n",
      "dp is:  0.09420044588136312\n",
      "ftu is:  0.04719125062140472\n",
      "prec : 0.9928335170893055\n",
      "rec : 0.9977839335180055\n",
      "roc : 0.9655586334256696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_synth = mlp.predict(X_synth)# Generate synthetic data\n",
    "X_synth_train, X_synth_test, y_synth_train, y_synth_test = train_test_split(X_synth, y_synth, test_size=2000, stratify=y_synth)\n",
    "\n",
    "dpmlp = MLPClassifier().fit(X_synth, y_synth)\n",
    "prec, rec, roc, acc = eval_model(dpmlp)\n",
    "print(\"prec :\", prec) \n",
    "print(\"rec :\", rec) \n",
    "print(\"roc :\", roc) \n",
    "\n",
    "ftu = cal_FTU(dpmlp, X_test=X_synth)\n",
    "dp = cal_DP(dpmlp, X_test=X_synth)\n",
    "print(\"dp is: \", dp)\n",
    "print(\"ftu is: \", ftu)\n",
    "\n",
    "\n",
    "# the weird thing they did in original code\n",
    "prec, rec, roc, acc = eval_model(dpmlp, X_synth_test, y_synth_test)\n",
    "print(\"prec :\", prec) \n",
    "print(\"rec :\", rec) \n",
    "print(\"roc :\", roc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate DECAF-CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec : 0.7654004106776181\n",
      "rec : 0.992676431424767\n",
      "roc : 0.5375028743469217\n",
      "dp is:  0.0005579566286761928\n",
      "ftu is:  0.003408848803352016\n",
      "prec : 0.7662796567390207\n",
      "rec : 0.9928057553956835\n",
      "roc : 0.5048954466999649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data\n",
    "X_synth, y_synth = generate_synthetic_data(biased_edges=bias_dict_cf)\n",
    "X_synth_train, X_synth_test, y_synth_train, y_synth_test = train_test_split(X_synth, y_synth, test_size=2000, stratify=y_synth)\n",
    "\n",
    "\n",
    "# Train downstream model and eval\n",
    "cfmlp = MLPClassifier().fit(X_synth_train, y_synth_train)\n",
    "eval_model(cfmlp)\n",
    "\n",
    "prec, rec, roc, acc = eval_model(cfmlp)\n",
    "print(\"prec :\", prec) \n",
    "print(\"rec :\", rec) \n",
    "print(\"roc :\", roc) \n",
    "\n",
    "ftu = cal_FTU(cfmlp, X_test=X_synth)\n",
    "dp = cal_DP(cfmlp, X_test=X_synth)\n",
    "print(\"dp is: \", dp)\n",
    "print(\"ftu is: \", ftu)\n",
    "\n",
    "# the weird thing they did in original code\n",
    "prec, rec, roc, acc = eval_model(cfmlp, X_synth_test, y_synth_test)\n",
    "print(\"prec :\", prec) \n",
    "print(\"rec :\", rec) \n",
    "print(\"roc :\", roc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec : 0.8670377241805813\n",
      "rec : 0.933422103861518\n",
      "roc : 0.7508475981154978\n",
      "dp is:  0.0006908918848490542\n",
      "ftu is:  0.0038349549037710595\n",
      "prec : 0.9944382647385984\n",
      "rec : 0.9021190716448032\n",
      "roc : 0.6732817580446238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_synth = cfmlp.predict(X_synth)# Generate synthetic data\n",
    "X_synth_train, X_synth_test, y_synth_train, y_synth_test = train_test_split(X_synth, y_synth, test_size=2000, stratify=y_synth)\n",
    "\n",
    "cfmlp = MLPClassifier().fit(X_synth_train, y_synth_train)\n",
    "prec, rec, roc, acc = eval_model(dpmlp)\n",
    "print(\"prec :\", prec) \n",
    "print(\"rec :\", rec) \n",
    "print(\"roc :\", roc) \n",
    "\n",
    "ftu = cal_FTU(cfmlp, X_test=X_synth)\n",
    "dp = cal_DP(cfmlp, X_test=X_synth)\n",
    "print(\"dp is: \", dp)\n",
    "print(\"ftu is: \", ftu)\n",
    "\n",
    "\n",
    "# the weird thing they did in original code\n",
    "prec, rec, roc, acc = eval_model(dpmlp, X_synth_test, y_synth_test)\n",
    "print(\"prec :\", prec) \n",
    "print(\"rec :\", rec) \n",
    "print(\"roc :\", roc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fairness Calcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dp is:  0.004991803404312156\n",
      "ftu is:  0.004793693629713713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "E:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ftu = cal_FTU(cfmlp, X_test=X_synth)\n",
    "dp = cal_DP(cfmlp, X_test=X_synth)\n",
    "print(\"dp is: \", dp)\n",
    "print(\"ftu is: \", ftu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
