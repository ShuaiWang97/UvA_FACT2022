{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduction of Adult dataset experiments\n",
    "\n",
    "In this notebook we reproduce the results from Table 2 of the DECAF paper. We compare various methods for generating debiased data using the DECAF model against synthetic data generated using benchmark models GAN, WGAN-GP and FairGAN. As described in the paper we run all experiments (as implemented in this notebook) 10 times and avarage the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from data import generate_synthetic_data, load_adult, preprocess_adult\n",
    "from metrics import DP, FTU\n",
    "from train import train_decaf, train_vanilla_gan, train_wgan_gp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preprocessing data\n",
    "\n",
    "We start off by downloading the Adult dataset, visualizing it and then preprocessing it in a form suitable for training the generative models which produce synthetic data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the Adult dataset and display a few examples from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country income  \n",
       "0          2174             0              40  United-States  <=50K  \n",
       "1             0             0              13  United-States  <=50K  \n",
       "2             0             0              40  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4             0             0              40           Cuba  <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display examples from the dataset\n",
    "adult_dataset = load_adult()\n",
    "adult_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next preprocess the data. Preprocessing is done by scaling all categorical feature values bettween 0 and 1. We also split the data in training and test sets where the test set has a size of 2000 as described in the original DECAF paper. Additionally we make sure that data is stratified so that the proportion of positive to negative examples is the same across the train and test folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.479452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106066</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070427</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215960</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.316327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.438356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123624</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.072981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.479452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148452</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1         2         3         4         5         6    7    8   \\\n",
       "0  0.479452  0.0  0.106066  0.066667  0.600000  0.333333  0.307692  0.6  0.0   \n",
       "1  0.068493  0.0  0.070427  0.066667  0.600000  0.333333  0.615385  0.6  0.0   \n",
       "2  0.027397  0.0  0.215960  0.200000  0.533333  0.333333  0.923077  0.6  0.0   \n",
       "3  0.438356  0.0  0.123624  0.066667  0.600000  0.000000  0.307692  0.4  0.0   \n",
       "4  0.479452  0.0  0.148452  0.600000  0.466667  0.000000  0.538462  0.4  0.0   \n",
       "\n",
       "    9         10   11        12   13   14  \n",
       "0  0.0  0.000000  0.0  0.500000  0.0  1.0  \n",
       "1  0.0  0.000000  0.0  0.346939  0.0  1.0  \n",
       "2  1.0  0.000000  0.0  0.316327  0.0  1.0  \n",
       "3  1.0  0.072981  0.0  0.397959  0.0  0.0  \n",
       "4  1.0  0.000000  0.0  0.448980  0.0  0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get training and testing data\n",
    "X, y = preprocess_adult(adult_dataset)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=2000, stratify=y)\n",
    "\n",
    "# Visualize train data and labels\n",
    "pd.DataFrame(data=np.column_stack((X_train, y_train))).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the DAG\n",
    "\n",
    "We also need to define a DAG which captures the biases of the dataset. As described in the DECAF paper normally a causal discovery algorithm is used. In this notebook we simply copy the DAG which as described in the Zhang et al. paper which is the one also used in the DECAF paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8, 6], [8, 14], [8, 12], [8, 3], [8, 5], [0, 6], [0, 12], [0, 14], [0, 1], [0, 5], [0, 3], [0, 7], [9, 6], [9, 5], [9, 14], [9, 1], [9, 3], [9, 7], [13, 5], [13, 12], [13, 3], [13, 1], [13, 14], [13, 7], [5, 6], [5, 12], [5, 14], [5, 1], [5, 7], [5, 3], [3, 6], [3, 12], [3, 14], [3, 1], [3, 7], [6, 14], [12, 14], [1, 14], [7, 14]]\n"
     ]
    }
   ],
   "source": [
    "# Define DAG for Adult dataset\n",
    "dag = [\n",
    "    # Edges from race\n",
    "    ['race', 'occupation'],\n",
    "    ['race', 'income'],\n",
    "    ['race', 'hours-per-week'],\n",
    "    ['race', 'education'],\n",
    "    ['race', 'marital-status'],\n",
    "\n",
    "    # Edges from age\n",
    "    ['age', 'occupation'],\n",
    "    ['age', 'hours-per-week'],\n",
    "    ['age', 'income'],\n",
    "    ['age', 'workclass'],\n",
    "    ['age', 'marital-status'],\n",
    "    ['age', 'education'],\n",
    "    ['age', 'relationship'],\n",
    "    \n",
    "    # Edges from sex\n",
    "    ['sex', 'occupation'],\n",
    "    ['sex', 'marital-status'],\n",
    "    ['sex', 'income'],\n",
    "    ['sex', 'workclass'],\n",
    "    ['sex', 'education'],\n",
    "    ['sex', 'relationship'],\n",
    "    \n",
    "    # Edges from native country\n",
    "    ['native-country', 'marital-status'],\n",
    "    ['native-country', 'hours-per-week'],\n",
    "    ['native-country', 'education'],\n",
    "    ['native-country', 'workclass'],\n",
    "    ['native-country', 'income'],\n",
    "    ['native-country', 'relationship'],\n",
    "    \n",
    "    # Edges from marital status\n",
    "    ['marital-status', 'occupation'],\n",
    "    ['marital-status', 'hours-per-week'],\n",
    "    ['marital-status', 'income'],\n",
    "    ['marital-status', 'workclass'],\n",
    "    ['marital-status', 'relationship'],\n",
    "    ['marital-status', 'education'],\n",
    "    \n",
    "    # Edges from education\n",
    "    ['education', 'occupation'],\n",
    "    ['education', 'hours-per-week'],\n",
    "    ['education', 'income'],\n",
    "    ['education', 'workclass'],\n",
    "    ['education', 'relationship'],\n",
    "    \n",
    "    # All remaining edges\n",
    "    ['occupation', 'income'],\n",
    "    ['hours-per-week', 'income'],\n",
    "    ['workclass', 'income'],\n",
    "    ['relationship', 'income'],\n",
    "]\n",
    "\n",
    "def dag_to_idx(df, dag):\n",
    "    \"\"\"Convert columns in a DAG to the corresponding indices.\"\"\"\n",
    "\n",
    "    dag_idx = []\n",
    "    for edge in dag:\n",
    "        dag_idx.append([df.columns.get_loc(edge[0]), df.columns.get_loc(edge[1])])\n",
    "\n",
    "    return dag_idx\n",
    "\n",
    "# Convert the DAG to one that can be provided to the DECAF model\n",
    "dag_seed = dag_to_idx(adult_dataset, dag)\n",
    "print(dag_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also necessary to define edges we want to remove from the DAG in order to meet the various fairness criteria described in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias dict FTU: {14: [9]}\n",
      "Bias dict DP: {14: [6, 12, 5, 3, 9, 1, 7]}\n",
      "Bias dict CF: {14: [5, 9]}\n"
     ]
    }
   ],
   "source": [
    "def create_bias_dict(df, edge_map):\n",
    "    \"\"\"\n",
    "    Convert the given edge tuples to a bias dict used for generating\n",
    "    debiased synthetic data.\n",
    "    \"\"\"\n",
    "    bias_dict = {}\n",
    "    for key, val in edge_map.items():\n",
    "        bias_dict[df.columns.get_loc(key)] = [df.columns.get_loc(f) for f in val]\n",
    "    \n",
    "    return bias_dict\n",
    "\n",
    "# Bias dictionary to satisfy FTU\n",
    "bias_dict_ftu = create_bias_dict(adult_dataset, {'income': ['sex']})\n",
    "print('Bias dict FTU:', bias_dict_ftu)\n",
    "\n",
    "# Bias dictionary to satisfy DP\n",
    "bias_dict_dp = create_bias_dict(adult_dataset, {'income': [\n",
    "    'occupation', 'hours-per-week', 'marital-status', 'education', 'sex',\n",
    "    'workclass', 'relationship']})\n",
    "print('Bias dict DP:', bias_dict_dp)\n",
    "\n",
    "# Bias dictionary to satisfy CF\n",
    "bias_dict_cf = create_bias_dict(adult_dataset, {'income': [\n",
    "    'marital-status', 'sex']})\n",
    "print('Bias dict CF:', bias_dict_cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "We have loaded and preprocessed the data and we are ready to run the experiments. For each experiment we train a generative model, sample synthetic data from the trained model and then obtain metrics by training and evaluating a downstream multi-layer perceptron using the test fold we generated in the previous section. We use the MLP model from `sklearn` with default parameters which matches the settings described in Appendix D of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(mlp, X_train, y_train, X_test=X_test, y_test=y_test):\n",
    "    \"\"\"Helper function that prints evaluation metrics.\"\"\"\n",
    "\n",
    "    y_pred = mlp.predict(X_test)\n",
    "\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    auroc = roc_auc_score(y_test, y_pred)\n",
    "    dp = DP(mlp, X_test)\n",
    "    ftu = FTU(X_train, y_train, X_test)\n",
    "\n",
    "    return {'precision': precision, 'recall': recall, 'auroc': auroc, 'dp': dp, 'ftu': ftu}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original dataset\n",
    "\n",
    "As a benchmark we want to first train the downstream model on the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/velizarshulev/Projects/UvA/UvA_FACT2022/env/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/velizarshulev/Projects/UvA/UvA_FACT2022/env/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.8639200998751561,\n",
       " 'recall': 0.9214380825565912,\n",
       " 'auroc': 0.7418435392702634,\n",
       " 'dp': 0.11743453851737821,\n",
       " 'ftu': 0.05407935884178032}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier().fit(X_train, y_train)\n",
    "eval_model(mlp, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following sections we train various models in order to reproduce the results from Table 2 of the DECAF paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-24 17:57:34.066734: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-01-24 17:57:34.272402: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]2022-01-24 17:57:35.168284: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      " 10%|█         | 1/10 [00:10<01:33, 10.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.000130, acc.: 100.00%] [G loss: 33.094780]\n",
      "generated_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:19<01:17,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [D loss: 0.000756, acc.: 100.00%] [G loss: 58.786240]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:28<01:06,  9.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 [D loss: 0.013608, acc.: 99.61%] [G loss: 86.380211]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:37<00:54,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 [D loss: 0.000005, acc.: 100.00%] [G loss: 101.344086]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:45<00:44,  8.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 [D loss: 0.000000, acc.: 100.00%] [G loss: 117.346016]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:55<00:35,  8.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 [D loss: 0.000000, acc.: 100.00%] [G loss: 129.285889]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [01:04<00:27,  9.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 [D loss: 0.000001, acc.: 100.00%] [G loss: 144.738297]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [01:15<00:19,  9.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 [D loss: 0.000000, acc.: 100.00%] [G loss: 162.553253]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [01:25<00:09,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 [D loss: 0.000000, acc.: 100.00%] [G loss: 174.425842]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:35<00:00,  9.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 [D loss: 0.000000, acc.: 100.00%] [G loss: 183.833832]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gan = train_vanilla_gan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Synthetic data generation: 100%|██████████| 236/236 [00:02<00:00, 103.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>41895</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-AF-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>373</td>\n",
       "      <td>-97</td>\n",
       "      <td>3</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>38613</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>11</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Other</td>\n",
       "      <td>Female</td>\n",
       "      <td>-41</td>\n",
       "      <td>-108</td>\n",
       "      <td>3</td>\n",
       "      <td>Nicaragua</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>40242</td>\n",
       "      <td>1st-4th</td>\n",
       "      <td>5</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>-92</td>\n",
       "      <td>2</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>47360</td>\n",
       "      <td>9th</td>\n",
       "      <td>2</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>45</td>\n",
       "      <td>-107</td>\n",
       "      <td>3</td>\n",
       "      <td>Holand-Netherlands</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>50762</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>4</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Amer-Indian-Eskimo</td>\n",
       "      <td>Female</td>\n",
       "      <td>-78</td>\n",
       "      <td>-96</td>\n",
       "      <td>4</td>\n",
       "      <td>Hungary</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     workclass  fnlwgt    education  education-num  \\\n",
       "0   18  Self-emp-inc   41895    Doctorate             13   \n",
       "1   19   Federal-gov   38613      HS-grad             11   \n",
       "2   18   Federal-gov   40242      1st-4th              5   \n",
       "3   19  Self-emp-inc   47360          9th              2   \n",
       "4   19   Federal-gov   50762  Prof-school              4   \n",
       "\n",
       "          marital-status         occupation   relationship  \\\n",
       "0      Married-AF-spouse      Other-service           Wife   \n",
       "1              Separated    Farming-fishing           Wife   \n",
       "2          Never-married  Machine-op-inspct  Not-in-family   \n",
       "3  Married-spouse-absent    Exec-managerial        Husband   \n",
       "4     Married-civ-spouse    Exec-managerial      Own-child   \n",
       "\n",
       "                 race     sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "0               Black    Male           373           -97               3   \n",
       "1               Other  Female           -41          -108               3   \n",
       "2  Asian-Pac-Islander  Female            27           -92               2   \n",
       "3               White  Female            45          -107               3   \n",
       "4  Amer-Indian-Eskimo  Female           -78           -96               4   \n",
       "\n",
       "       native-country income  \n",
       "0              Taiwan   >50K  \n",
       "1           Nicaragua  <=50K  \n",
       "2            Thailand   >50K  \n",
       "3  Holand-Netherlands   >50K  \n",
       "4             Hungary   >50K  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synth_df = gan.sample(len(adult_dataset))\n",
    "X_synth, y_synth = preprocess_adult(synth_df)\n",
    "synth_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/velizarshulev/Projects/UvA/UvA_FACT2022/env/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/velizarshulev/Projects/UvA/UvA_FACT2022/env/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/velizarshulev/Projects/UvA/UvA_FACT2022/env/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.696866485013624,\n",
       " 'recall': 0.6810918774966711,\n",
       " 'auroc': 0.39375879015395804,\n",
       " 'dp': 0.2678333332484898,\n",
       " 'ftu': 0.19709672372361148}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier().fit(X_synth, y_synth)\n",
    "eval_model(mlp, X_synth, y_synth, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WGAN-GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:04<00:44,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | disc_loss: 1.0493888854980469 | gen_loss: 0.0024936457630246878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:07<00:27,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | disc_loss: 4.879275321960449 | gen_loss: 0.010172907263040543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:09<00:21,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | disc_loss: 5.498307228088379 | gen_loss: 0.010316535830497742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:13<00:18,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | disc_loss: 0.6758951544761658 | gen_loss: 0.03112035244703293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:17<00:16,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | disc_loss: 0.051433153450489044 | gen_loss: 0.05552292615175247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:21<00:14,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | disc_loss: -0.024509325623512268 | gen_loss: 0.04996667802333832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:24<00:11,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | disc_loss: -0.029461752623319626 | gen_loss: 0.0560053326189518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:28<00:07,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | disc_loss: 0.4348539113998413 | gen_loss: 0.06448204070329666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:32<00:03,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | disc_loss: 0.3692534863948822 | gen_loss: 0.0648110881447792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:35<00:00,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | disc_loss: -0.0524517185986042 | gen_loss: 0.07477548718452454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "wgan_gp = train_wgan_gp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Synthetic data generation: 100%|██████████| 61/61 [00:01<00:00, 40.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>59756</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Other</td>\n",
       "      <td>Male</td>\n",
       "      <td>-9466</td>\n",
       "      <td>189</td>\n",
       "      <td>34</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>33796</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>5</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Female</td>\n",
       "      <td>-6891</td>\n",
       "      <td>-48</td>\n",
       "      <td>39</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>18129</td>\n",
       "      <td>Masters</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>-13059</td>\n",
       "      <td>200</td>\n",
       "      <td>38</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>46350</td>\n",
       "      <td>5th-6th</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Female</td>\n",
       "      <td>-13165</td>\n",
       "      <td>122</td>\n",
       "      <td>43</td>\n",
       "      <td>Japan</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>26969</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>12</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>-10135</td>\n",
       "      <td>223</td>\n",
       "      <td>45</td>\n",
       "      <td>Peru</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt    education  education-num marital-status  \\\n",
       "0   48         Local-gov   59756    Assoc-voc             11      Separated   \n",
       "1   53      Self-emp-inc   33796  Prof-school              5       Divorced   \n",
       "2   51         Local-gov   18129      Masters              9       Divorced   \n",
       "3   51       Federal-gov   46350      5th-6th             10  Never-married   \n",
       "4   58  Self-emp-not-inc   26969  Prof-school             12      Separated   \n",
       "\n",
       "          occupation   relationship                race     sex  capital-gain  \\\n",
       "0    Exec-managerial      Own-child               Other    Male         -9466   \n",
       "1              Sales           Wife  Asian-Pac-Islander  Female         -6891   \n",
       "2  Handlers-cleaners      Own-child               White    Male        -13059   \n",
       "3   Transport-moving  Not-in-family  Asian-Pac-Islander  Female        -13165   \n",
       "4      Other-service      Own-child               Black  Female        -10135   \n",
       "\n",
       "   capital-loss  hours-per-week native-country income  \n",
       "0           189              34        Ireland   >50K  \n",
       "1           -48              39         Taiwan   >50K  \n",
       "2           200              38           Cuba   >50K  \n",
       "3           122              43          Japan   >50K  \n",
       "4           223              45           Peru  <=50K  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synth_df = wgan_gp.sample(len(adult_dataset))\n",
    "X_synth, y_synth = preprocess_adult(synth_df)\n",
    "synth_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/velizarshulev/Projects/UvA/UvA_FACT2022/env/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/velizarshulev/Projects/UvA/UvA_FACT2022/env/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/velizarshulev/Projects/UvA/UvA_FACT2022/env/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/velizarshulev/Projects/UvA/UvA_FACT2022/env/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.6913099870298314,\n",
       " 'recall': 0.3548601864181092,\n",
       " 'auroc': 0.43847426991588195,\n",
       " 'dp': 0.328974925705189,\n",
       " 'ftu': 0.22759274591220616}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier().fit(X_synth, y_synth)\n",
    "eval_model(mlp, X_synth, y_synth, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DECAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/velizarshulev/Projects/UvA/UvA_FACT2022/env/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:175: LightningDeprecationWarning: DataModule property `dims` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  rank_zero_deprecation(\"DataModule property `dims` was deprecated in v1.5 and will be removed in v1.7.\")\n",
      "/Users/velizarshulev/Projects/UvA/UvA_FACT2022/env/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:170: LightningDeprecationWarning: DataModule property `dims` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  rank_zero_deprecation(\"DataModule property `dims` was deprecated in v1.5 and will be removed in v1.7.\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/Users/velizarshulev/Projects/UvA/UvA_FACT2022/env/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:120: UserWarning: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "  rank_zero_warn(\"You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\")\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | generator     | Generator_causal | 134 K \n",
      "1 | discriminator | Discriminator    | 43.6 K\n",
      "---------------------------------------------------\n",
      "178 K     Trainable params\n",
      "225       Non-trainable params\n",
      "178 K     Total params\n",
      "0.713     Total estimated model params size (MB)\n",
      "/Users/velizarshulev/Projects/UvA/UvA_FACT2022/env/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /Users/velizarshulev/Projects/UvA/UvA_FACT2022/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "/Users/velizarshulev/Projects/UvA/UvA_FACT2022/env/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised adjacency matrix as parsed:\n",
      " Parameter containing:\n",
      "tensor([[0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1.],\n",
      "        [0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "Epoch 9: 100%|██████████| 441/441 [00:10<00:00, 42.58it/s, loss=-0.204]\n"
     ]
    }
   ],
   "source": [
    "model, dm = train_decaf(X_train, y_train, dag_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.078750</td>\n",
       "      <td>6.898178e-05</td>\n",
       "      <td>0.193788</td>\n",
       "      <td>0.292212</td>\n",
       "      <td>0.670328</td>\n",
       "      <td>0.585060</td>\n",
       "      <td>0.589974</td>\n",
       "      <td>0.924082</td>\n",
       "      <td>8.088188e-06</td>\n",
       "      <td>0.003137</td>\n",
       "      <td>0.002240</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.101669</td>\n",
       "      <td>5.560403e-13</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.058457</td>\n",
       "      <td>1.623612e-08</td>\n",
       "      <td>0.232570</td>\n",
       "      <td>0.027444</td>\n",
       "      <td>0.712811</td>\n",
       "      <td>0.345917</td>\n",
       "      <td>0.129528</td>\n",
       "      <td>0.570842</td>\n",
       "      <td>1.574450e-09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021018</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.494674</td>\n",
       "      <td>3.081539e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.185823</td>\n",
       "      <td>4.318405e-09</td>\n",
       "      <td>0.125791</td>\n",
       "      <td>0.105664</td>\n",
       "      <td>0.572919</td>\n",
       "      <td>0.460711</td>\n",
       "      <td>0.078483</td>\n",
       "      <td>0.490799</td>\n",
       "      <td>6.685104e-18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>0.542236</td>\n",
       "      <td>2.943965e-06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.164186</td>\n",
       "      <td>4.411560e-06</td>\n",
       "      <td>0.032183</td>\n",
       "      <td>0.164686</td>\n",
       "      <td>0.491094</td>\n",
       "      <td>0.054120</td>\n",
       "      <td>0.185706</td>\n",
       "      <td>0.322611</td>\n",
       "      <td>9.678963e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001666</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.550422</td>\n",
       "      <td>2.928007e-01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.532269</td>\n",
       "      <td>4.156069e-08</td>\n",
       "      <td>0.138216</td>\n",
       "      <td>0.328320</td>\n",
       "      <td>0.637247</td>\n",
       "      <td>0.368350</td>\n",
       "      <td>0.715154</td>\n",
       "      <td>0.793034</td>\n",
       "      <td>1.608216e-07</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.014398</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.447102</td>\n",
       "      <td>2.268934e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0             1         2         3         4         5         6   \\\n",
       "0  0.078750  6.898178e-05  0.193788  0.292212  0.670328  0.585060  0.589974   \n",
       "1  0.058457  1.623612e-08  0.232570  0.027444  0.712811  0.345917  0.129528   \n",
       "2  0.185823  4.318405e-09  0.125791  0.105664  0.572919  0.460711  0.078483   \n",
       "3  0.164186  4.411560e-06  0.032183  0.164686  0.491094  0.054120  0.185706   \n",
       "4  0.532269  4.156069e-08  0.138216  0.328320  0.637247  0.368350  0.715154   \n",
       "\n",
       "         7             8         9         10        11        12  \\\n",
       "0  0.924082  8.088188e-06  0.003137  0.002240  0.000161  0.101669   \n",
       "1  0.570842  1.574450e-09  1.000000  0.021018  0.000955  0.494674   \n",
       "2  0.490799  6.685104e-18  1.000000  0.004792  0.002169  0.542236   \n",
       "3  0.322611  9.678963e-01  1.000000  0.001666  0.000007  0.550422   \n",
       "4  0.793034  1.608216e-07  0.002404  0.014398  0.000922  0.447102   \n",
       "\n",
       "             13   14  \n",
       "0  5.560403e-13  1.0  \n",
       "1  3.081539e-07  1.0  \n",
       "2  2.943965e-06  0.0  \n",
       "3  2.928007e-01  1.0  \n",
       "4  2.268934e-07  1.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_synth, y_synth = generate_synthetic_data(model, dm)\n",
    "pd.DataFrame(data=np.column_stack((X_synth, y_synth))).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DECAF-ND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/velizarshulev/Projects/UvA/UvA_FACT2022/env/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/velizarshulev/Projects/UvA/UvA_FACT2022/env/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/velizarshulev/Projects/UvA/UvA_FACT2022/env/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.7733473242392445,\n",
       " 'recall': 0.9813581890812251,\n",
       " 'auroc': 0.5569441547815763,\n",
       " 'dp': 0.3019233015366842,\n",
       " 'ftu': 0.1274305204685909}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_synth, y_synth = generate_synthetic_data(model, dm)\n",
    "mlp = MLPClassifier().fit(X_synth, y_synth)\n",
    "eval_model(mlp, X_synth, y_synth, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "13e45f1d2a71a5202f039caac1b9c752d2af996637e618c185f277d12109b1e8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
