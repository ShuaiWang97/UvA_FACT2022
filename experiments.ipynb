{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a900cb30",
   "metadata": {},
   "source": [
    "# Reproduction of DECAF: Generating Fair Synthetic Data Using Causally-Aware Generative Networks\n",
    "\n",
    "In this notebook we reproduce the results from the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "955b1c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aafa8e9",
   "metadata": {},
   "source": [
    "## Loading the Adult dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "c15523f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_adult():\n",
    "    \"\"\"Load the Adult dataset in a pandas dataframe\"\"\"\n",
    "\n",
    "    path = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "    names = [\n",
    "        \"age\",\n",
    "        \"workclass\",\n",
    "        \"fnlwgt\",\n",
    "        \"education\",\n",
    "        \"education-num\",\n",
    "        \"marital-status\",\n",
    "        \"occupation\",\n",
    "        \"relationship\",\n",
    "        \"race\",\n",
    "        \"sex\",\n",
    "        \"capital-gain\",\n",
    "        \"capital-loss\",\n",
    "        \"hours-per-week\",\n",
    "        \"native-country\",\n",
    "        \"income\",\n",
    "    ]\n",
    "    df = pd.read_csv(path, names=names, index_col=False)\n",
    "    df = df.applymap(lambda x: x.strip() if type(x) is str else x)\n",
    "\n",
    "    for col in df:\n",
    "        if df[col].dtype == \"object\":\n",
    "            df = df[df[col] != \"?\"]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "6f7687b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country income  \n",
       "0          2174             0              40  United-States  <=50K  \n",
       "1             0             0              13  United-States  <=50K  \n",
       "2             0             0              40  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4             0             0              40           Cuba  <=50K  "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display examples from the dataset\n",
    "adult_dataset = load_adult()\n",
    "adult_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "b2a5fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test_data(df):\n",
    "    \"\"\"Get GAN training data from Adult dataset\"\"\"\n",
    "    replace = [\n",
    "        [\n",
    "            \"Private\",\n",
    "            \"Self-emp-not-inc\",\n",
    "            \"Self-emp-inc\",\n",
    "            \"Federal-gov\",\n",
    "            \"Local-gov\",\n",
    "            \"State-gov\",\n",
    "            \"Without-pay\",\n",
    "            \"Never-worked\",\n",
    "        ],\n",
    "        [\n",
    "            \"Bachelors\",\n",
    "            \"Some-college\",\n",
    "            \"11th\",\n",
    "            \"HS-grad\",\n",
    "            \"Prof-school\",\n",
    "            \"Assoc-acdm\",\n",
    "            \"Assoc-voc\",\n",
    "            \"9th\",\n",
    "            \"7th-8th\",\n",
    "            \"12th\",\n",
    "            \"Masters\",\n",
    "            \"1st-4th\",\n",
    "            \"10th\",\n",
    "            \"Doctorate\",\n",
    "            \"5th-6th\",\n",
    "            \"Preschool\",\n",
    "        ],\n",
    "        [\n",
    "            \"Married-civ-spouse\",\n",
    "            \"Divorced\",\n",
    "            \"Never-married\",\n",
    "            \"Separated\",\n",
    "            \"Widowed\",\n",
    "            \"Married-spouse-absent\",\n",
    "            \"Married-AF-spouse\",\n",
    "        ],\n",
    "        [\n",
    "            \"Tech-support\",\n",
    "            \"Craft-repair\",\n",
    "            \"Other-service\",\n",
    "            \"Sales\",\n",
    "            \"Exec-managerial\",\n",
    "            \"Prof-specialty\",\n",
    "            \"Handlers-cleaners\",\n",
    "            \"Machine-op-inspct\",\n",
    "            \"Adm-clerical\",\n",
    "            \"Farming-fishing\",\n",
    "            \"Transport-moving\",\n",
    "            \"Priv-house-serv\",\n",
    "            \"Protective-serv\",\n",
    "            \"Armed-Forces\",\n",
    "        ],\n",
    "        [\n",
    "            \"Wife\",\n",
    "            \"Own-child\",\n",
    "            \"Husband\",\n",
    "            \"Not-in-family\",\n",
    "            \"Other-relative\",\n",
    "            \"Unmarried\",\n",
    "        ],\n",
    "        [\"White\", \"Asian-Pac-Islander\", \"Amer-Indian-Eskimo\", \"Other\", \"Black\"],\n",
    "        [\"Female\", \"Male\"],\n",
    "        [\n",
    "            \"United-States\",\n",
    "            \"Cambodia\",\n",
    "            \"England\",\n",
    "            \"Puerto-Rico\",\n",
    "            \"Canada\",\n",
    "            \"Germany\",\n",
    "            \"Outlying-US(Guam-USVI-etc)\",\n",
    "            \"India\",\n",
    "            \"Japan\",\n",
    "            \"Greece\",\n",
    "            \"South\",\n",
    "            \"China\",\n",
    "            \"Cuba\",\n",
    "            \"Iran\",\n",
    "            \"Honduras\",\n",
    "            \"Philippines\",\n",
    "            \"Italy\",\n",
    "            \"Poland\",\n",
    "            \"Jamaica\",\n",
    "            \"Vietnam\",\n",
    "            \"Mexico\",\n",
    "            \"Portugal\",\n",
    "            \"Ireland\",\n",
    "            \"France\",\n",
    "            \"Dominican-Republic\",\n",
    "            \"Laos\",\n",
    "            \"Ecuador\",\n",
    "            \"Taiwan\",\n",
    "            \"Haiti\",\n",
    "            \"Columbia\",\n",
    "            \"Hungary\",\n",
    "            \"Guatemala\",\n",
    "            \"Nicaragua\",\n",
    "            \"Scotland\",\n",
    "            \"Thailand\",\n",
    "            \"Yugoslavia\",\n",
    "            \"El-Salvador\",\n",
    "            \"Trinadad&Tobago\",\n",
    "            \"Peru\",\n",
    "            \"Hong\",\n",
    "            \"Holand-Netherlands\",\n",
    "        ],\n",
    "        [\">50K\", \"<=50K\"],\n",
    "    ]\n",
    "\n",
    "    for row in replace:\n",
    "        df = df.replace(row, range(len(row)))\n",
    "\n",
    "    df = df.values\n",
    "    X = df[:, :].astype(np.uint32)\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    y = df[:, 14].astype(np.uint8)\n",
    "\n",
    "    return train_test_split(X, y, test_size=2000, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "67068f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DAG for Adult dataset\n",
    "dag = [\n",
    "    # Edges from race\n",
    "    ['race', 'occupation'],\n",
    "    ['race', 'income'],\n",
    "    ['race', 'hours-per-week'],\n",
    "    ['race', 'education'],\n",
    "    ['race', 'marital-status'],\n",
    "\n",
    "    # Edges from age\n",
    "    ['age', 'occupation'],\n",
    "    ['age', 'hours-per-week'],\n",
    "    ['age', 'income'],\n",
    "    ['age', 'workclass'],\n",
    "    ['age', 'marital-status'],\n",
    "    ['age', 'education'],\n",
    "    ['age', 'relationship'],\n",
    "    \n",
    "    # Edges from sex\n",
    "    ['sex', 'occupation'],\n",
    "    ['sex', 'marital-status'],\n",
    "    ['sex', 'income'],\n",
    "    ['sex', 'workclass'],\n",
    "    ['sex', 'education'],\n",
    "    ['sex', 'relationship'],\n",
    "    \n",
    "    # Edges from native country\n",
    "    ['native-country', 'marital-status'],\n",
    "    ['native-country', 'hours-per-week'],\n",
    "    ['native-country', 'education'],\n",
    "    ['native-country', 'workclass'],\n",
    "    ['native-country', 'income'],\n",
    "    ['native-country', 'relationship'],\n",
    "    \n",
    "    # Edges from marital status\n",
    "    ['marital-status', 'occupation'],\n",
    "    ['marital-status', 'hours-per-week'],\n",
    "    ['marital-status', 'income'],\n",
    "    ['marital-status', 'workclass'],\n",
    "    ['marital-status', 'relationship'],\n",
    "    ['marital-status', 'education'],\n",
    "    \n",
    "    # Edges from education\n",
    "    ['education', 'occupation'],\n",
    "    ['education', 'hours-per-week'],\n",
    "    ['education', 'income'],\n",
    "    ['education', 'workclass'],\n",
    "    ['education', 'relationship'],\n",
    "    \n",
    "    # All remaining edges\n",
    "    ['occupation', 'income'],\n",
    "    ['hours-per-week', 'income'],\n",
    "    ['workclass', 'income'],\n",
    "    ['relationship', 'income'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "53abc2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dag_to_idx(df, dag):\n",
    "    \"\"\"Convert columns in a DAG to the corresponding indices.\"\"\"\n",
    "\n",
    "    dag_idx = []\n",
    "    for edge in dag:\n",
    "        dag_idx.append([df.columns.get_loc(edge[0]), df.columns.get_loc(edge[1])])\n",
    "\n",
    "    return dag_idx\n",
    "\n",
    "def create_bias_dict(df, edge_map):\n",
    "    \"\"\"\n",
    "    Convert the given edge tuples to a bias dict used for generating\n",
    "    debiased synthetic data.\n",
    "    \"\"\"\n",
    "    bias_dict = {}\n",
    "    for key, val in edge_map.items():\n",
    "        bias_dict[df.columns.get_loc(key)] = [df.columns.get_loc(f) for f in val]\n",
    "    \n",
    "    return bias_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "8850bfe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8, 6], [8, 14], [8, 12], [8, 3], [8, 5], [0, 6], [0, 12], [0, 14], [0, 1], [0, 5], [0, 3], [0, 7], [9, 6], [9, 5], [9, 14], [9, 1], [9, 3], [9, 7], [13, 5], [13, 12], [13, 3], [13, 1], [13, 14], [13, 7], [5, 6], [5, 12], [5, 14], [5, 1], [5, 7], [5, 3], [3, 6], [3, 12], [3, 14], [3, 1], [3, 7], [6, 14], [12, 14], [1, 14], [7, 14]]\n"
     ]
    }
   ],
   "source": [
    "# Convert the DAG to one that can be provided to the DECAF model\n",
    "dag_seed = dag_to_idx(adult_dataset, dag)\n",
    "print(dag_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "4eac8ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias dict FTU: {14: [9]}\n",
      "Bias dict DP: {14: [6, 12, 5, 3, 9, 1, 7]}\n",
      "Bias dict CF: {14: [5, 9]}\n"
     ]
    }
   ],
   "source": [
    "bias_dict_ftu = create_bias_dict(adult_dataset, {'income': ['sex']})\n",
    "print('Bias dict FTU:', bias_dict_ftu)\n",
    "\n",
    "bias_dict_dp = create_bias_dict(adult_dataset, {'income': [\n",
    "    'occupation', 'hours-per-week', 'marital-status', 'education', 'sex',\n",
    "    'workclass', 'relationship']})\n",
    "print('Bias dict DP:', bias_dict_dp)\n",
    "\n",
    "bias_dict_cf = create_bias_dict(adult_dataset, {'income': [\n",
    "    'marital-status', 'sex']})\n",
    "print('Bias dict CF:', bias_dict_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "6f585fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and testing data\n",
    "X_train, X_test, y_train, y_test = load_train_test_data(adult_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9f18b3",
   "metadata": {},
   "source": [
    "## Evaluate on original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "81076e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/velizarshulev/Projects/UvA/UvA_FACT2022/env/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Train an MLP\n",
    "mlp = MLPClassifier().fit(X_train[:, :14], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "58780b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8927875243664717 0.914780292942743 0.7917274958689617\n"
     ]
    }
   ],
   "source": [
    "# Evaluate original data\n",
    "y_pred = mlp.predict(X_test[:, :14])\n",
    "\n",
    "print(\n",
    "    precision_score(y_test, y_pred),\n",
    "    recall_score(y_test, y_pred),\n",
    "    roc_auc_score(y_test, y_pred),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61021fa",
   "metadata": {},
   "source": [
    "## DECAF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb82233c",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "5e4f8787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/velizarshulev/Projects/UvA/UvA_FACT2022/env/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:175: LightningDeprecationWarning: DataModule property `dims` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  rank_zero_deprecation(\"DataModule property `dims` was deprecated in v1.5 and will be removed in v1.7.\")\n",
      "/Users/velizarshulev/Projects/UvA/UvA_FACT2022/env/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:170: LightningDeprecationWarning: DataModule property `dims` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  rank_zero_deprecation(\"DataModule property `dims` was deprecated in v1.5 and will be removed in v1.7.\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/Users/velizarshulev/Projects/UvA/UvA_FACT2022/env/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:120: UserWarning: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "  rank_zero_warn(\"You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\")\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | generator     | Generator_causal | 134 K \n",
      "1 | discriminator | Discriminator    | 43.6 K\n",
      "---------------------------------------------------\n",
      "178 K     Trainable params\n",
      "225       Non-trainable params\n",
      "178 K     Total params\n",
      "0.713     Total estimated model params size (MB)\n",
      "/Users/velizarshulev/Projects/UvA/UvA_FACT2022/env/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /Users/velizarshulev/Projects/UvA/UvA_FACT2022/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "/Users/velizarshulev/Projects/UvA/UvA_FACT2022/env/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised adjacency matrix as parsed:\n",
      " Parameter containing:\n",
      "tensor([[0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1.],\n",
      "        [0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "Epoch 9: 100%|██████████| 441/441 [00:09<00:00, 45.54it/s, loss=-2.73]\n"
     ]
    }
   ],
   "source": [
    "from models.DECAF import DECAF\n",
    "from data import DataModule\n",
    "\n",
    "dm = DataModule(X_train)\n",
    "\n",
    "model = DECAF(\n",
    "    dm.dims[0],\n",
    "    dag_seed=dag_seed,\n",
    "    h_dim=200,\n",
    "    lr=0.5e-3,\n",
    "    batch_size=64,\n",
    "    lambda_privacy=0,\n",
    "    lambda_gp=10,\n",
    "    d_updates=10,\n",
    "    alpha=2,\n",
    "    rho=2,\n",
    "    weight_decay=1e-2,\n",
    "    grad_dag_loss=False,\n",
    "    l1_g=0,\n",
    "    l1_W=1e-4,\n",
    "    p_gen=-1,\n",
    "    use_mask=True,\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=10, logger=False)\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "f9594f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(biased_edges={}):\n",
    "    \"\"\"Generate synthetic data which is also optionally debiased.\"\"\"\n",
    "    X_synth = (\n",
    "        model.gen_synthetic(\n",
    "            dm.dataset.x,\n",
    "            gen_order=model.get_gen_order(),\n",
    "            biased_edges=biased_edges,\n",
    "        )\n",
    "        .detach()\n",
    "        .numpy()\n",
    "    )\n",
    "\n",
    "    X_synth = np.rint(X_synth)\n",
    "\n",
    "    y_synth = X_synth[:,14]\n",
    "\n",
    "    return X_synth[:, :14].astype(np.uint32), y_synth.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "f6306e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(mlp):\n",
    "    \"\"\"Helper function that prints evaluation metrics.\"\"\"\n",
    "\n",
    "    y_pred = mlp.predict(X_test[:, :14])\n",
    "\n",
    "    print('Precision:', precision_score(y_test, y_pred))\n",
    "    print('Recall:', recall_score(y_test, y_pred))\n",
    "    print('AUROC:', roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a92d88",
   "metadata": {},
   "source": [
    "### Evaluate DECAF-ND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "c2eb496a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9175891758917589\n",
      "Recall: 0.4966711051930759\n",
      "AUROC: 0.6810664762913171\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data\n",
    "X_synth, y_synth = generate_synthetic_data()\n",
    "\n",
    "# Train downstream model\n",
    "mlp = MLPClassifier().fit(X_synth, y_synth)\n",
    "\n",
    "# Evaluate\n",
    "eval_model(mlp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bffe3c",
   "metadata": {},
   "source": [
    "### Evaluate DECAF-FTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "6d2127d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9563636363636364\n",
      "Recall: 0.35019973368841545\n",
      "AUROC: 0.6510034813020391\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data\n",
    "X_synth, y_synth = generate_synthetic_data(biased_edges=bias_dict_ftu)\n",
    "\n",
    "# Train downstream model\n",
    "mlp = MLPClassifier().fit(X_synth, y_synth)\n",
    "\n",
    "# Evaluate\n",
    "eval_model(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b3717b",
   "metadata": {},
   "source": [
    "### Evaluate DECAF-DP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "bc0eb681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.936\n",
      "Recall: 0.31158455392809586\n",
      "AUROC: 0.623663762907823\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data\n",
    "X_synth, y_synth = generate_synthetic_data(biased_edges=bias_dict_dp)\n",
    "\n",
    "# Train downstream model\n",
    "mlp = MLPClassifier().fit(X_synth, y_synth)\n",
    "\n",
    "# Evaluate\n",
    "eval_model(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd35a956",
   "metadata": {},
   "source": [
    "### Evaluate DECAF-CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "4b64030e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.939209726443769\n",
      "Recall: 0.41145139813581894\n",
      "AUROC: 0.6655650564976283\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data\n",
    "X_synth, y_synth = generate_synthetic_data(biased_edges=bias_dict_cf)\n",
    "\n",
    "# Train downstream model\n",
    "mlp = MLPClassifier().fit(X_synth, y_synth)\n",
    "\n",
    "# Evaluate\n",
    "eval_model(mlp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
